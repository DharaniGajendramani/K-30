# ------------------------------------------
# Crop Yield Prediction using Real Dataset
# ------------------------------------------

import pandas as pd
import numpy as np
import joblib
import os

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    mean_squared_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
)
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor

# -------------------------
# Load dataset
# -------------------------
file_path = "/content/crop_yield_dataset.csv"  # <-- ensure this CSV is in your working directory
data = pd.read_csv(file_path)

print("âœ… Dataset loaded successfully!")
print(data.head())

# -------------------------
# Split features and target
# -------------------------
X = data.drop("yield", axis=1)
y = data["yield"]

# Identify numeric and categorical columns
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()

# -------------------------
# Preprocessing pipelines
# -------------------------
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),   # handle missing numeric values
    ('scaler', StandardScaler())                   # scale values
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # handle missing categorical values
    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # convert categories into numbers
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

# -------------------------
# Define base and stacking models
# -------------------------
base_models = [
    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),
    ('gb', GradientBoostingRegressor(random_state=42))
]

stacking_model = StackingRegressor(
    estimators=base_models,
    final_estimator=LinearRegression(),
    passthrough=True
)

# Full pipeline (preprocessing + model)
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', stacking_model)
])

# -------------------------
# Train-test split
# -------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
pipeline.fit(X_train, y_train)

# -------------------------
# Regression evaluation
# -------------------------
y_pred = pipeline.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nðŸ“Š Regression Performance:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# -------------------------
# Classification evaluation (High vs Low yield)
# -------------------------
threshold = y_train.median()

y_test_class = (y_test >= threshold).astype(int)
y_pred_class = (y_pred >= threshold).astype(int)

accuracy = accuracy_score(y_test_class, y_pred_class)
precision = precision_score(y_test_class, y_pred_class)
recall = recall_score(y_test_class, y_pred_class)
f1 = f1_score(y_test_class, y_pred_class)
roc_auc = roc_auc_score(y_test_class, y_pred)

print("\nðŸ“Š Classification Performance (High vs Low Yield):")
print(f"âœ… Accuracy  : {accuracy:.2f}")
print(f"âœ… Precision : {precision:.2f}")
print(f"âœ… Recall    : {recall:.2f}")
print(f"âœ… F1 Score  : {f1:.2f}")
print(f"âœ… ROC-AUC   : {roc_auc:.2f}")

# -------------------------
# Save trained model
# -------------------------
model_dir = "saved_models"
os.makedirs(model_dir, exist_ok=True)

model_path = os.path.join(model_dir, "crop_yield_stacking_model.pkl")
joblib.dump(pipeline, model_path)

print(f"\nâœ… Model saved at: {model_path}")

# -------------------------
# Optional: Download model (for Google Colab users)
# -------------------------
try:
    from google.colab import files
    files.download(model_path)
    print("\nâ¬‡ Model download started...")
except ImportError:
    print("\nâš  Not running in Google Colab. Please manually download the model from:", model_path)
